The role of the human being in relationship to the LLM agents operating their behalf is quintessential to what the human can rely - and can not rely on - from those agents.  

One way to look at this is to ask "whom does the agent serve?".  On the surface, it may seem obvious that an agent serves the person who is using it. But this superficial assumption is both naive and frequently incorrect.

Here is an overview of how this plays out from a consumer context (written for the Consumer Reports Innovation Lab): [https://www.dazzagreenwood.com/p/empowering-consumers-with-personal](https://www.dazzagreenwood.com/p/empowering-consumers-with-personal)

Notably, this question is equally important from the perspective of companies or other organizations using and relying upon AI Agents, expecially when those agents are conducting transactions that may incur payments or other legal obligations.  The ideal alignment is for the providers and operators of AI Agents to be fiduciaries to the direct user of the AI Agent.  This ensures the duty of loyalty applied and that the communications and actions of the AI Agent will align with the interests of that user.

![Page Under Construction](../assets/images/under-construction-1.gif)
