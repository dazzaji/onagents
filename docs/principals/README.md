# Who Wields Principal Authority Over AI Agents?

The role of the human being in relationship to the LLM agents operating their behalf is quintessential to what the human can rely on - and can not rely on - from those agents.  

One way to look at this is to ask "whom does the agent serve?".  On the surface, it may seem obvious that an agent serves the person who is using it. But this superficial assumption is both naive and frequently incorrect.

Here is an overview of how this plays out from a consumer context (written for the Consumer Reports Innovation Lab): [https://www.dazzagreenwood.com/p/empowering-consumers-with-personal](https://www.dazzagreenwood.com/p/empowering-consumers-with-personal)

Notably, this question is equally important from the perspective of companies or other organizations using and relying upon AI Agents, expecially when those agents are conducting transactions that may incur payments or other legal obligations.  The ideal alignment is for the providers and operators of AI Agents to be fiduciaries to the direct user of the AI Agent.  This ensures the duty of loyalty applied and that the communications and actions of the AI Agent will align with the interests of that user.

I will use this page to provide a deeper discussion, with examples, of how the legal concept of "principal authority" can clarify and form a workable basis for trustworthy reliance upon the communications and actions of agents.

For the moment, you can learn more about the concept of Principal Authority over agents in the "The Iron Triangle: Principal, Agent, and Third Party" section on the [Agent Transactions](https://onagents.org/transactions) area of this site.

![Page Under Construction](../assets/images/under-construction-1.gif)
